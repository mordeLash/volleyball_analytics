{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5659a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Actual ball diameter in meters (e.g., Volleyball is ~0.21m)\n",
    "BALL_REAL_DIAMETER = 0.21 \n",
    "NET_HEIGHT = 2.43\n",
    "# Define your real-world coordinates for your labels (X, Y, Z)\n",
    "# Z = 0 is the ground. Let's assume the net height is 2.43m.\n",
    "world_points_map = {\n",
    "    \"BE_LEFT\":       [0.0, 0.0, 0.0   ],\n",
    "    \"BA_LEFT\":       [0.0, 6.0, 0.0   ],\n",
    "    \"M_LEFT\":        [0.0, 9.0, 0.0   ],\n",
    "    \"TA_LEFT\":       [0.0, 12.0, 0.0  ],\n",
    "    \"TE_LEFT\":       [0.0, 18.0, 0.0  ],\n",
    "    \"NET_B_LEFT\":    [0.0, 9.0, NET_HEIGHT-1],\n",
    "    \"NET_T_LEFT\":    [0.0, 9.0, NET_HEIGHT], \n",
    "    \"ANT_T_LEFT\":    [0.0, 9.0, NET_HEIGHT+0.8],\n",
    "    \"BE_RIGHT\":      [9.0, 0.0, 0.0   ],\n",
    "    \"BA_RIGHT\":      [9.0, 6.0, 0.0   ],\n",
    "    \"M_RIGHT\":       [9.0, 9.0, 0.0   ],\n",
    "    \"TA_RIGHT\":      [9.0, 12.0, 0.0  ],\n",
    "    \"TE_RIGHT\":      [9.0, 18.0, 0.0  ],\n",
    "    \"NET_B_RIGHT\": [9.0, 9.0, NET_HEIGHT-1],\n",
    "    \"NET_T_RIGHT\":   [9.0, 9.0, NET_HEIGHT],\n",
    "    \"ANT_T_RIGHT\": [9.0, 9.0, NET_HEIGHT+0.8],\n",
    "}\n",
    "# BA_RIGHT,1467.015,754.13\n",
    "# BA_LEFT,323.559,668.08\n",
    "# M_RIGHT,1587.646,687.474\n",
    "# M_RIGHT,575.877,634.642\n",
    "# NET_T_RIGHT,1563.401,324.402\n",
    "# NET_T_LEFT,573.488,369.349\n",
    "# TA_RIGHT,1660.031,645.074\n",
    "# NET_B_RIGHT,1576.133,478.926\n",
    "# NET_B_LEFT,576.6,483.066\n",
    "# Data from your CSV (name, img_x, img_y)\n",
    "collected_data = [\n",
    "    (\"BA_RIGHT\", 1467.015,754.13),\n",
    "    (\"BA_LEFT\", 323.559,668.08),\n",
    "    (\"M_RIGHT\", 1587.646,687.474),\n",
    "    (\"M_LEFT\", 575.877,634.642),\n",
    "    (\"NET_T_RIGHT\", 1563.401,324.402),\n",
    "    (\"NET_T_LEFT\",573.488,369.349),\n",
    "    (\"TA_RIGHT\",1660.031,645.074)\n",
    "]\n",
    "collected_data = [\n",
    "    (\"BE_RIGHT\",903.709,861.078,),\n",
    "    (\"BA_RIGHT\",1295.086,742.611,),\n",
    "    (\"M_RIGHT\",1399.292,711.481,),\n",
    "    (\"BA_LEFT\",450.494,688.182,),\n",
    "    (\"M_LEFT\",585.012,671.832,),\n",
    "    (\"TA_RIGHT\",1556.239,664.584,),\n",
    "    (\"NET_T_RIGHT\",1395.733,446.422,),\n",
    "    # (\"NET_B_RIGHT\",1399.577,551.74,),\n",
    "    # (\"ANT_T_RIGHT\",1391.42,358.154,),\n",
    "    # (\"NET_B_LEFT\",638.214,547.15,),\n",
    "    (\"NET_T_LEFT\",639.631,462.495,),\n",
    "    # (\"ANT_T_LEFT\" ,641.402,393.07,),\n",
    "]\n",
    "collected_data = [\n",
    "    (\"TE_LEFT\",465.565,519.4940),\n",
    "    (\"TA_LEFT\",321.796,601.733),\n",
    "    (\"BA_LEFT\",1.132,781.967),\n",
    "    (\"M_RIGHT\",1420.885,636.213),\n",
    "    (\"TE_RIGHT\",1184.41,501.596),\n",
    "    (\"TA_RIGHT\",1312.372,575.302),\n",
    "    (\"M_LEFT\",193.865,671.834),\n",
    "    (\"BA_RIGHT\",1585.02,728.349),\n",
    "    (\"NET_T_LEFT\" ,164.882,319.697),\n",
    "    (\"NET_T_RIGHT\",1428.694,302.609),\n",
    "]\n",
    "collected_data = [\n",
    "    (\"BE_LEFT\",1248.824,876.159),\n",
    "   (\"BA_LEFT\",812.639,776.17),\n",
    "   (\"M_LEFT\",686.566,748.637),\n",
    "   (\"BA_RIGHT\",1607.148,696.992),\n",
    "   (\"TE_LEFT\",512.393,710.208),\n",
    "   (\"TA_LEFT\",610.407,733.987),\n",
    "   (\"M_RIGHT\",1423.955,687.176),\n",
    "   (\"NET_T_RIGHT\",1413.493,480.536),\n",
    "   (\"NET_T_LEFT\",678.291,493.482),\n",
    "\n",
    "]\n",
    "collected_data = [\n",
    "    (\"BA_LEFT\",991.204,1278.692),\n",
    "   (\"BA_RIGHT\",2812.985,1281.593),\n",
    "   (\"M_LEFT\",1165.259,1014.708),\n",
    "   (\"M_RIGHT\",2644.731,1014.708),\n",
    "   (\"TA_LEFT\",1271.05,831.604),\n",
    "   (\"TA_RIGHT\",2534.906,834.014),\n",
    "   (\"TE_RIGHT\",2390.327,589.436),\n",
    "   (\"TE_LEFT\",1420.447,589.436),\n",
    "   (\"NET_T_RIGHT\",2712.014,644.857),\n",
    "   (\"NET_T_LEFT\",1098.642,642.059),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a98647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(data, world_map, img_w=1920, img_h=1080,focal_length = None):\n",
    "    image_pts = []\n",
    "    object_pts = []\n",
    "    \n",
    "    # Only use points that exist in BOTH your CSV data and your world_map\n",
    "    for name, ix, iy in data:\n",
    "        if name in world_map:\n",
    "            image_pts.append([ix, iy])\n",
    "            object_pts.append(world_map[name])\n",
    "        else:\n",
    "            print(f\"Warning: Point '{name}' in data but not defined in world_map. Skipping.\")\n",
    "            \n",
    "    if len(image_pts) < 4:\n",
    "        raise ValueError(f\"Need at least 4 points to calibrate. Found {len(image_pts)}.\")\n",
    "\n",
    "    image_pts = np.array(image_pts, dtype=np.float32)\n",
    "    object_pts = np.array(object_pts, dtype=np.float32)\n",
    "\n",
    "    # Intrinsics: Use a focal length guess. \n",
    "    # For many wide-angle cameras, focal_length â‰ˆ image_width\n",
    "    if(focal_length==None):\n",
    "        focal_length = img_w\n",
    "    center = (img_w / 2, img_h / 2)\n",
    "    \n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    dist_coeffs = np.zeros((4, 1)) \n",
    "\n",
    "    # solvePnP finds the camera position/rotation relative to the court\n",
    "    success, rvec, tvec = cv2.solvePnP(\n",
    "        object_pts, \n",
    "        image_pts, \n",
    "        camera_matrix, \n",
    "        dist_coeffs, \n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    \n",
    "    if not success:\n",
    "        print(\"Calibration failed!\")\n",
    "        return None, None, None\n",
    "\n",
    "    return camera_matrix, rvec, tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a600ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ball_height(ball_x, ball_y, ball_w_px, camera_matrix, rvec, tvec):\n",
    "    \"\"\"\n",
    "    Calculates the 3D position and height of the ball.\n",
    "    Uses the pixel width to determine distance (Z depth from camera).\n",
    "    \"\"\"\n",
    "    f_x = camera_matrix[0, 0]\n",
    "    \n",
    "    # 1. Calculate distance from camera using the apparent width\n",
    "    # distance = (focal_length * real_width) / width_in_pixels\n",
    "    distance_from_cam = (f_x * BALL_REAL_DIAMETER) / ball_w_px\n",
    "    \n",
    "    # 2. Get Normalized Image Coordinates\n",
    "    cx, cy = camera_matrix[0, 2], camera_matrix[1, 2]\n",
    "    x_norm = (ball_x - cx) / f_x\n",
    "    y_norm = (ball_y - cy) / camera_matrix[1, 1]\n",
    "    \n",
    "    # 3. Ball position in Camera Space\n",
    "    P_cam = np.array([x_norm * distance_from_cam, \n",
    "                      y_norm * distance_from_cam, \n",
    "                      distance_from_cam])\n",
    "    \n",
    "    # 4. Transform Camera Space to World Space\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    # P_world = R_inv * (P_cam - T)\n",
    "    P_world = np.dot(R.T, (P_cam - tvec.flatten()))\n",
    "    \n",
    "    return P_world # Return the Z-coordinate (Height)\n",
    "\n",
    "def verify_calibration(camera_matrix, rvec, tvec, world_map):\n",
    "    # Convert world points to a numpy array\n",
    "    names = list(world_map.keys())\n",
    "    pts_3d = np.array([world_map[n] for n in names], dtype=np.float32)\n",
    "    \n",
    "    # Project 3D points to 2D image plane\n",
    "    img_pts, _ = cv2.projectPoints(pts_3d, rvec, tvec, camera_matrix, np.zeros((4,1)))\n",
    "    \n",
    "    for i, name in enumerate(names):\n",
    "        print(f\"Point {name}: World {world_map[name]} -> Image {img_pts[i].ravel()}\")\n",
    "    return img_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de45d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_homography(camera_matrix, rvec, tvec):\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    \n",
    "    # Normally for ground (Z=0), we take columns 0 and 1 of R.\n",
    "    # For the Net (Y=9), the plane is defined by X and Z.\n",
    "    # So we take column 0 (X) and column 2 (Z).\n",
    "    \n",
    "    # We also need to account for the fact that Y is not 0, it's 9.\n",
    "    # The translation becomes: t_effective = (R * [0, 9, 0]^T) + tvec\n",
    "    y_offset_world = np.array([0, 9.0, 0], dtype=np.float32).reshape(3, 1)\n",
    "    t_effective = np.dot(R, y_offset_world) + tvec\n",
    "    \n",
    "    # Combine Column 0 (X), Column 2 (Z), and the effective translation\n",
    "    rt_vertical = np.column_stack((R[:, 0], R[:, 2], t_effective))\n",
    "    \n",
    "    # H = K * [r1 r3 t_eff]\n",
    "    h_net = np.dot(camera_matrix, rt_vertical)\n",
    "    \n",
    "    return np.linalg.inv(h_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3d0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_net_coords(u, v, h_net_inv):\n",
    "    \"\"\"Convert pixel (u, v) to world (X, Z) on the net plane.\"\"\"\n",
    "    pixel_pt = np.array([u, v, 1.0], dtype=np.float32)\n",
    "    world_pt = np.dot(h_net_inv, pixel_pt)\n",
    "    \n",
    "    world_pt /= world_pt[2] # Normalize\n",
    "    return world_pt[0], world_pt[1] # Returns X and Z (Height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001aaf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_world_ground(u, v, h_inv):\n",
    "    \"\"\"Convert pixel (u, v) to world (X, Y) assuming it's on the ground.\"\"\"\n",
    "    pixel_pt = np.array([u, v, 1.0], dtype=np.float32)\n",
    "    world_pt = np.dot(h_inv, pixel_pt)\n",
    "    \n",
    "    # Normalize by the third coordinate (scale factor)\n",
    "    world_pt /= world_pt[2]\n",
    "    return world_pt[0], world_pt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02759ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_homography(camera_matrix, rvec, tvec):\n",
    "    \"\"\"\n",
    "    Creates a Homography matrix that maps image pixels (u, v) \n",
    "    directly to ground coordinates (X, Y, 0).\n",
    "    \"\"\"\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    \n",
    "    # The transformation matrix from World to Camera is [R | t]\n",
    "    # We only care about the mapping to the Z=0 plane\n",
    "    # So we take columns 1, 2, and 4 of the projection matrix\n",
    "    rt_extrinsic = np.column_stack((R[:, 0], R[:, 1], tvec))\n",
    "    \n",
    "    # H = K * [r1 r2 t]\n",
    "    homography = np.dot(camera_matrix, rt_extrinsic)\n",
    "    \n",
    "    # We want the inverse to go from Image -> World\n",
    "    h_inv = np.linalg.inv(homography)\n",
    "    return h_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8012fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_homography_overlay(image, cam_mtx, rvec, tvec):\n",
    "    overlay = image.copy()\n",
    "    \n",
    "    # 1. FLOOR OVERLAY (Green)\n",
    "    # Define the 4 corners of the court floor in World Space (X, Y, Z=0)\n",
    "    floor_corners = np.array([\n",
    "        [0, 0, 0], [9, 0, 0], [9, 18, 0], [0, 18, 0]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Project floor to image\n",
    "    floor_img_pts, _ = cv2.projectPoints(floor_corners, rvec, tvec, cam_mtx, np.zeros((4,1)))\n",
    "    floor_img_pts = floor_img_pts.reshape(-1, 2).astype(np.int32)\n",
    "    \n",
    "    # Draw floor polygon\n",
    "    cv2.fillPoly(overlay, [floor_img_pts], (0, 255, 0)) # Green floor\n",
    "\n",
    "    # 2. NET OVERLAY (Blue)\n",
    "    # Define the 4 corners of the net plane in World Space (X, Y=9, Z)\n",
    "    net_corners = np.array([\n",
    "        [0, 9, 0], [9, 9, 0], [9, 9, NET_HEIGHT], [0, 9, NET_HEIGHT]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Project net to image\n",
    "    net_img_pts, _ = cv2.projectPoints(net_corners, rvec, tvec, cam_mtx, np.zeros((4,1)))\n",
    "    net_img_pts = net_img_pts.reshape(-1, 2).astype(np.int32)\n",
    "    \n",
    "    # Draw net polygon\n",
    "    cv2.fillPoly(overlay, [net_img_pts], (255, 0, 0)) # Blue net\n",
    "\n",
    "    # 3. Blend overlay with original image\n",
    "    alpha = 0.3  # Transparency factor\n",
    "    return cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "218294bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Image Pt: [573.488,369.349]\n",
      "Projected 3D Net Pt: [1113.3717   638.76025]\n",
      "Error is[-539.8837041  -269.41125391] \n",
      "the Ground Point is at: (1.3894238188747292, 13.85355593430862)\n",
      "the Net Point is at: (2.623439923072273, 4.238237195560694)\n",
      "--- 3D World Position of Net Center ---\n",
      "X: -8.17m, Y: 30.53m, Z (Height): -0.10m\n"
     ]
    }
   ],
   "source": [
    "# --- OPTIMIZATION STEP ---\n",
    "\n",
    "\n",
    "cam_mtx, rvec, tvec = calibrate_camera(collected_data, world_points_map, img_w=3840, img_h=2160)\n",
    "\n",
    "if cam_mtx is not None:\n",
    "    # 1. Project the Net Top Left to see if it matches the image\n",
    "    net_tl_world = np.array([world_points_map[\"NET_T_LEFT\"]], dtype=np.float32)\n",
    "    projected_pt, _ = cv2.projectPoints(net_tl_world, rvec, tvec, cam_mtx, np.zeros((4,1)))\n",
    "    print(f\"Actual Image Pt: [573.488,369.349]\")\n",
    "    print(f\"Projected 3D Net Pt: {projected_pt.ravel()}\")\n",
    "    print(f\"Error is{[573.488,369.349] - projected_pt.ravel()} \")\n",
    "\n",
    "    # 2. Get the full 3D position of the \"detected\" net center\n",
    "    # Note: net_w here acts as the 'real diameter' scale\n",
    "    ball_x = (1110.581 + 410.468) / 2\n",
    "    ball_y = (236.174 + 265.529) / 2\n",
    "    ball_w_px = 19\n",
    "    h_inv = get_ground_homography(cam_mtx,rvec,tvec)\n",
    "    nh_inv = get_net_homography(cam_mtx,rvec,tvec)\n",
    "    world_p = image_to_world_ground(1467.015,754.13,h_inv)\n",
    "    world_p2 = image_to_net_coords(1563.401,324.402,nh_inv)\n",
    "    # Using your function (ensure BALL_REAL_DIAMETER is set to net width, e.g., 9.0m)\n",
    "    # We temporarily override the diameter constant for the net calculation\n",
    "    P_world = get_ball_height(ball_x, ball_y, ball_w_px, cam_mtx, rvec, tvec)\n",
    "    print(f\"the Ground Point is at: {world_p}\")\n",
    "    print(f\"the Net Point is at: {world_p2}\")\n",
    "    print(f\"--- 3D World Position of Net Center ---\")\n",
    "    print(f\"X: {P_world[0]:.2f}m, Y: {P_world[1]:.2f}m, Z (Height): {P_world[2]:.2f}m\")\n",
    "    img = cv2.imread(r\"C:\\Users\\morde\\Desktop\\volleyball\\raw footage\\netball_imgs\\net_ball1_frame_1450.jpg\") \n",
    "if img is not None:\n",
    "    # Resize image to match the img_w/img_h used in calibration if necessary\n",
    "    img = cv2.resize(img, (3840, 2160))\n",
    "    \n",
    "    # Generate the visualization\n",
    "    result_img = draw_homography_overlay(img, cam_mtx, rvec, tvec)\n",
    "    \n",
    "    # Add dots for your collected_data points for verification\n",
    "    for name, ix, iy in collected_data:\n",
    "        cv2.circle(result_img, (int(ix), int(iy)), 5, (0, 0, 255), -1)\n",
    "        cv2.putText(result_img, name, (int(ix)+10, int(iy)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Calibration Overlay\", result_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10afdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_ball_data_by_track(input_path, output_path, cam_mtx, rvec, tvec, window_size=5, fps=30):\n",
    "    \"\"\"\n",
    "    Processes multi-track detections:\n",
    "    - Preserves all original columns.\n",
    "    - Groups by 'track_id' to prevent cross-track smoothing.\n",
    "    - Uses Median filter for outlier rejection.\n",
    "    \"\"\"\n",
    "    # 1. Load data\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    # Ensure data is sorted by track and then frame for rolling window\n",
    "    df = df.sort_values(by=['track_id', 'frame']).reset_index(drop=True)\n",
    "    \n",
    "    # 2. Pre-calculate the average size (Diameter)\n",
    "    df['avg_size'] = (df['w'] + df['h']) / 2\n",
    "    \n",
    "    # 3. Apply Smoothing PER TRACK\n",
    "    # We use groupby('track_id') so the window resets for every new ball/player\n",
    "    grouped = df.groupby('track_id', group_keys=False)\n",
    "\n",
    "    def smooth_group(group):\n",
    "        # Rolling Median to kill outliers, followed by a small Mean to smooth quantization\n",
    "        for col in ['avg_size', 'cx', 'cy']:\n",
    "            median_val = group[col].rolling(window=window_size, center=True, min_periods=1).median()\n",
    "            group[f'smoothed_{col}'] = median_val.rolling(window=3, center=True, min_periods=1).mean()\n",
    "        return group\n",
    "\n",
    "    df = grouped.apply(smooth_group)\n",
    "\n",
    "    # 4. Convert 2D Smoothed points to 3D World Coordinates\n",
    "    # (Applying the function row-by-row)\n",
    "    def row_to_3d(row):\n",
    "        # Ensure your get_ball_height function is defined globally\n",
    "        return get_ball_height(\n",
    "            row['smoothed_cx'], \n",
    "            row['smoothed_cy'], \n",
    "            row['smoothed_avg_size'], \n",
    "            cam_mtx, rvec, tvec\n",
    "        )\n",
    "\n",
    "    # Calculate 3D points\n",
    "    world_points = df.apply(row_to_3d, axis=1)\n",
    "    df[['world_x', 'world_y', 'world_z']] = pd.DataFrame(world_points.tolist(), index=df.index)\n",
    "\n",
    "    # 5. Calculate Speed PER TRACK\n",
    "    def calculate_speed(group):\n",
    "        # Calculate diffs within the group\n",
    "        dx = group['world_x'].diff()\n",
    "        dy = group['world_y'].diff()\n",
    "        dz = group['world_z'].diff()\n",
    "        \n",
    "        dist = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "        raw_speed = dist * fps * 3.6\n",
    "        \n",
    "        # Apply median filter to speed to ignore single-frame tracking jumps\n",
    "        group['speed_kph'] = raw_speed.rolling(window=window_size, center=True, min_periods=1).median()\n",
    "        return group\n",
    "\n",
    "    df = df.groupby('track_id', group_keys=False).apply(calculate_speed)\n",
    "\n",
    "    # 6. Save (All original columns + new 3D/Speed columns)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Processed {len(df)} rows across {df['track_id'].nunique()} tracks.\")\n",
    "\n",
    "# --- Usage ---\n",
    "# process_ball_data_by_track(\"detections.csv\", \"output_3d_multi_track.csv\", cam_mtx, rvec, tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3427cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morde\\AppData\\Local\\Temp\\ipykernel_22236\\480794346.py:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = grouped.apply(smooth_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15923 rows across 97 tracks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morde\\AppData\\Local\\Temp\\ipykernel_22236\\480794346.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('track_id', group_keys=False).apply(calculate_speed)\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "INPUT_CSV = r\"C:\\Users\\morde\\Desktop\\volleyball\\raw footage\\table_data\\netball_set1_detections_cleaned.csv\"      # Your input file with cx, cy, w, h\n",
    "OUTPUT_CSV = \"ball_coords_net_3d.csv\"     # Where the 3D data will be saved\n",
    "BALL_REAL_DIAMETER = 0.21   \n",
    "# --- MAIN EXECUTION ---\n",
    "\n",
    "# 1. Perform Calibration (from your snippet)\n",
    "cam_mtx, rvec, tvec = calibrate_camera(collected_data, world_points_map, img_w=3840, img_h=2160)\n",
    "\n",
    "if cam_mtx is not None:\n",
    "    # 2. Run the processing pipeline\n",
    "    process_ball_data_by_track(INPUT_CSV, OUTPUT_CSV, cam_mtx, rvec, tvec)\n",
    "else:\n",
    "    print(\"Error: Camera calibration failed. Check your collected_data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce3b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
